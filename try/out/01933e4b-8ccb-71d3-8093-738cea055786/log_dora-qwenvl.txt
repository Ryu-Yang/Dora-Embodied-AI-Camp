2024-11-18 16:02:41.901485: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-18 16:02:42.733297: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|����������     | 1/2 [00:00<00:00,  4.40it/s]Loading checkpoint shards: 100%|��������������������| 2/2 [00:00<00:00,  5.60it/s]Loading checkpoint shards: 100%|��������������������| 2/2 [00:00<00:00,  5.38it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Users\fuyus\AppData\Roaming\Python\Python311\Scripts\dora-qwenvl.exe\__main__.py", line 7, in <module>
  File "C:\Users\fuyus\AppData\Roaming\Python\Python311\site-packages\dora_qwenvl\main.py", line 168, in main
    response = generate(frames, question)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fuyus\AppData\Roaming\Python\Python311\site-packages\dora_qwenvl\main.py", line 86, in generate
    inputs = inputs.to("cuda")
             ^^^^^^^^^^^^^^^^^
  File "C:\Users\fuyus\AppData\Roaming\Python\Python311\site-packages\transformers\feature_extraction_utils.py", line 244, in to
    new_data[k] = v.to(device=device)
                  ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fuyus\AppData\Roaming\Python\Python311\site-packages\torch\cuda\__init__.py", line 305, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
